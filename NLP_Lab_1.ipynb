{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evlko/CS-388/blob/main/NLP_Lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUuyLVDZ4s8r"
      },
      "source": [
        "## LABORATY WORK 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwJ5Q6w2IFHA"
      },
      "source": [
        "**Source link**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64uxt-07IEec"
      },
      "source": [
        "DATA_URL = \"http://lib.ru/LITRA/PUSHKIN/dubrowskij.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwrBkeLnHuA1"
      },
      "source": [
        "Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Fr5swwYfz5"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q keras==2.2.4\n",
        "!pip install -q 'h5py<3.0.0'\n",
        "!pip install -q -U numpy==1.18.5\n",
        "!pip install -q tensorflow==1.15.2\n",
        "!pip install -q PyYaml==5.3.1\n",
        "!pip install -q rnnmorph==0.4.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbxMKqhPH1Dk"
      },
      "source": [
        "Initialize a morphological analyzer object `RNNMorph`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24zMUhvi99AV"
      },
      "source": [
        "from rnnmorph.predictor import RNNMorphPredictor\n",
        "predictor = RNNMorphPredictor(language=\"ru\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59q1L9p0H9K9"
      },
      "source": [
        "Download the text for the task using `urllib`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uW0fw_h-Pft"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "opener = urllib.request.URLopener({})\n",
        "resource = opener.open(DATA_URL)\n",
        "raw_text = resource.read().decode(resource.headers.get_content_charset())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Raw Text:"
      ],
      "metadata": {
        "id": "WosHx37rvEfo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "-hSPOjDo4sdh",
        "outputId": "f01066e7-931d-4d86-9605-5bfaca013d83"
      },
      "source": [
        "raw_text[:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<html><head><title>Александр Сергеевич Пушкин. Дубровский</title></head><body><pre><div align=right><form action=/LITRA/PUSHKIN/dubrowskij.txt><select name=format><OPTION VALUE=\"_Contents\">Содержание<'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZiLHQNSITAt"
      },
      "source": [
        "The text contains html tags which should be removed. Stripping HTML tags from text using the `Beatiful soap` lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We4LkyUMPfuq"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(raw_text, features=\"html.parser\")\n",
        "\n",
        "# kill all script and style elements\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()    # rip it out\n",
        "\n",
        "# get text\n",
        "cleaned_text = soup.get_text()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleand Text:"
      ],
      "metadata": {
        "id": "3l1xg5P8vTyS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "lOD8PJnG4rbl",
        "outputId": "ab2976dd-f4a0-47e5-d0ce-892f2fc230d3"
      },
      "source": [
        "cleaned_text[:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Александр Сергеевич Пушкин. ДубровскийСодержаниеFine HTMLPrinted versiontxt(Word,КПК)Lib.ru html\\nАлександр Сергеевич Пушкин. Дубровский\\n\\n---------------------------------------------------------------'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14fYYb5hIpnY"
      },
      "source": [
        "Using [NLTK](https://nltk.org/) lib we strip the text into sentences and tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "hRNu7jPvN6G_",
        "outputId": "631f944d-bd67-429d-e026-4e6b3f33eaf9"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sent_tokenize(cleaned_text)]\n",
        "\"A total of %d 'sentences'\" % len(tokenized_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"A total of 1426 'sentences'\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRU4KEBAIyYT"
      },
      "source": [
        "## Task 1\n",
        "Using `str.isalpha` function from the Python standard library only literal tokens remain in predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U5HH2CDPVUM",
        "outputId": "44be4cf7-0206-4d72-fd08-e1f1bd096ea7"
      },
      "source": [
        "from tqdm import tqdm\n",
        "predictions = [[pred.normal_form for pred in sent if str(pred.normal_form).isalpha()] \n",
        "               for sent in tqdm(predictor.predict_sentences(sentences=tokenized_sentences), \"sentences\")]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sentences: 100%|██████████| 1426/1426 [00:00<00:00, 58722.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Sentences:"
      ],
      "metadata": {
        "id": "veSFTOr9v5Nm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwK_qRbw6sac",
        "outputId": "82dad8db-79f0-4494-ef90-6a66ec3fc295"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1426"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Tokens:"
      ],
      "metadata": {
        "id": "oa-61Aguv7UA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5jL4sWyKUnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e4c736-7dad-45f9-dc1d-2d712fea209a"
      },
      "source": [
        "non_uniq_tokens = [word for sentence in predictions for word in sentence]\n",
        "len(non_uniq_tokens) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20410"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mci9Nd5hKuJP"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "Using `non_uniq_tokens`, russian stop words from nltk (`nltk.corpus.stopwords`) lib and `nltk.FreqDist`, calculate, **what proportion of the 50 most frequent** tokens in the product is occupied by tokens **not related** to stop words.\n",
        "\n",
        "**For example**, if among the 100 most frequent words there are 25 words included in the stop list, then 75 words are not included in the stop list, and their share will be 0.75."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHbtLqkLKfZC",
        "outputId": "051530e0-731d-4fbd-b816-b77fc056c26d"
      },
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "STOPWORDS = set(stopwords.words(\"russian\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop words examples:"
      ],
      "metadata": {
        "id": "LqeLYXnowpeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(STOPWORDS)[:5] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvSVN-_awrrD",
        "outputId": "b9f9732e-f890-4568-b4e7-51dcae393791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['без', 'кто', 'куда', 'сейчас', 'впрочем']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "\n",
        "def take(n, iterable):\n",
        "    return list(islice(iterable, n))\n",
        "\n",
        "fdist = FreqDist(non_uniq_tokens)\n",
        "\n",
        "n = 50\n",
        "words = fdist.most_common()[:n]\n",
        "s = 0\n",
        "\n",
        "for word in words:\n",
        "  if word[0] not in STOPWORDS:\n",
        "    s += 1\n",
        "\n",
        "s / n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsGrmfFv2X-6",
        "outputId": "9c16b27f-5164-4a1a-b25e-5eaa6cada75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HChyAdk2Ovx1"
      },
      "source": [
        "## Task 3\n",
        "Calculate how many tokens occur in the text **strictly more than** 20 times."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = fdist.most_common()\n",
        "c = 0\n",
        "\n",
        "for word in words:\n",
        "  if word[1] > 20:\n",
        "    c += 1\n",
        "  else:\n",
        "    break\n",
        "\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBlykAiBaqy9",
        "outputId": "5932af6b-882c-4cba-8f55-1317b3dc7dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}