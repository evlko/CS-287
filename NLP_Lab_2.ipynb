{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evlko/CS-388/blob/main/NLP_Lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_ST0GfO97y"
      },
      "source": [
        "# LABORATY WORK 2 (Information Search)\n",
        "Downloading the Classic Dataset - Aeronautics Textset CRANFIELD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHflLH2APAHK",
        "outputId": "6db9ff48-9257-4681-bfe0-0658a39424a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cran.all.1400\n",
            "cran.qry\n",
            "cranqrel\n",
            "cranqrel.readme\n"
          ]
        }
      ],
      "source": [
        "! wget -q http://ir.dcs.gla.ac.uk/resources/test_collections/cran/cran.tar.gz\n",
        "! tar -xvf cran.tar.gz\n",
        "! rm cran.tar.gz*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYuND83cPR5D"
      },
      "source": [
        "Take only the requests themselves (these will be our documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6owW-L7zhJws",
        "outputId": "e50307c1-265f-4421-80b0-fb5a318d55d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what similarity laws must be obeyed when constructing aeroelastic models\r\n",
            "of heated high speed aircraft .\r\n",
            "what are the structural and aeroelastic problems associated with flight\r\n"
          ]
        }
      ],
      "source": [
        "! grep -v \"^\\.\" cran.qry > just.qry\n",
        "! head -3 just.qry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZbUb6FmQxr1"
      },
      "source": [
        "Combine multiline into one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBaV3xeQiUam",
        "outputId": "7d0b56ab-e0d7-4ba5-c153-53c1714f7c80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft . ',\n",
              " 'what are the structural and aeroelastic problems associated with flight of high speed aircraft . ']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "raw_query_data = [line.strip() for line in open(\"just.qry\", \"r\").readlines()]\n",
        "query_data = [\"\"]\n",
        "\n",
        "for query_part in raw_query_data:\n",
        "  query_data[-1] += query_part + \" \"\n",
        "  if query_part.endswith(\".\"):\n",
        "    query_data.append(\"\")\n",
        "\n",
        "query_data[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLFq_6lBki3S"
      },
      "source": [
        "### Queires to our documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "h3sgHjWkjjR1"
      },
      "outputs": [],
      "source": [
        "QUERIES = ['viscous interactions']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQMdH0HSkoJg"
      },
      "source": [
        "## Boolean retrieval\n",
        "Let's represent each document as a \"bitmask\": a vector the size of a dictionary, in which each position is one if the document has a corresponding term, and zero if there is no term."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhrI18rZSLLz"
      },
      "outputs": [],
      "source": [
        "! pip install -q scikit-learn==0.22.2.post1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbTOdsHIknD0",
        "outputId": "50bd7d56-1805-48c9-edec-43877cea3a6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'similarity', 'laws']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from  sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "encoder = CountVectorizer(binary=True)\n",
        "encoded_data = encoder.fit_transform(query_data)\n",
        "encoded_queries = encoder.transform(QUERIES)\n",
        "list(encoder.vocabulary_)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUdwKDKSTjdD"
      },
      "source": [
        "Let's look at the presentation of the first sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXEmXErylJdX",
        "outputId": "437f4c06-6010-4cea-c4ec-311c79c9764c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what',\n",
              " 'similarity',\n",
              " 'laws',\n",
              " 'must',\n",
              " 'be',\n",
              " 'obeyed',\n",
              " 'when',\n",
              " 'constructing',\n",
              " 'aeroelastic',\n",
              " 'models',\n",
              " 'of',\n",
              " 'heated',\n",
              " 'high',\n",
              " 'speed',\n",
              " 'aircraft']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "id2term = {idx: term for term, idx in encoder.vocabulary_.items()}\n",
        "non_zero_values_ids = encoded_data[0].nonzero()[1]\n",
        "\n",
        "terms = [id2term[idx] for idx in non_zero_values_ids]\n",
        "terms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8wdS9XiVwb2"
      },
      "source": [
        "## Task 0\n",
        "\n",
        "Now for each of these `QUERIES` queries, we will find the closest document for it from `query_data` by Jaccard's similarity. There are better ways to do this, but you need to implement the Jaccard distance and then apply it to our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "u31WuBYAUWt2"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "\n",
        "def jaccard_sim(vector_a: np.array, vector_b: np.array) -> float:\n",
        "  \"\"\"\n",
        "    Similarity or Jaccard Coefficient: ratio of the intersect power\n",
        "    to the union power\n",
        "  \"\"\"\n",
        "  return sum(vector_a * vector_b) / (sum(vector_a) + sum(vector_b) - sum(vector_a * vector_b))\n",
        "  \n",
        "# Simple text\n",
        "assert jaccard_sim(np.array([1, 0, 1, 0, 1]), np.array([0, 1, 1, 1, 1])) == 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o5XhK6MfxYk"
      },
      "source": [
        "Here the documents are represented in the same way as the rows in the matrix of document-terms. Each cell of the vector is responsible for the presence / absence of a specific element (for example, a term word, when we have only 5 words in the dictionary). In the first case there are 3, in the second there are 4. The union is all 5 possible elements. Intersection is 2. Hence the ratio is 2/5 or just 0.4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYfQksWrOR1G"
      },
      "source": [
        "## Task 1\n",
        "Compute for each query the closest documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4okpFpA6OAQs",
        "outputId": "76899925-44e4-436e-c557-941536cf4522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: viscous interactions\n",
            "FOUND:\n",
            "    44\t0.15\thas anyone investigated the effect of surface mass transfer on hypersonic viscous interactions . \n",
            "    46\t0.14\twhat are the existing solutions for hypersonic viscous interactions over an insulated flat plate . \n",
            "    70\t0.14\texperimental results on hypersonic viscous interaction . \n"
          ]
        }
      ],
      "source": [
        "for q_id, query in enumerate(encoded_queries):\n",
        "  # cast to the desired type\n",
        "  query = query.todense().A1\n",
        "  docs = [doc.todense().A1 for doc in encoded_data]\n",
        "  # calc jaccard sim\n",
        "  id2doc2similarity = [(doc_id, doc, jaccard_sim(query, doc)) for doc_id, doc in enumerate(docs)]\n",
        "  # sort\n",
        "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=True)\n",
        "  \n",
        "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
        "  for closest_id, _, sim in closest[:3]:\n",
        "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Fh8RdvOrAD"
      },
      "source": [
        "We see that in some places texts are leaking, which are combined with queries by insignificant terms, but at the same time the Jaccard coefficient - our ranking function! - is high.\n",
        "\n",
        "# VSM\n",
        "\n",
        "Let's try to do the same now, but with tf-idf and cosine distance. We will do everything again \"by hand\", but \"in real life\" it is better to use efficient implementations of cosine distance, for example, from the scipy library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmpKMI08E2iO",
        "outputId": "7c8feec3-e004-496f-e6ec-a7aa2fb74bbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'similarity', 'laws']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_encoder = TfidfVectorizer()\n",
        "tfidf_encoded_data = tfidf_encoder.fit_transform(query_data)\n",
        "tfidf_encoded_queries = tfidf_encoder.transform(QUERIES)\n",
        "\n",
        "list(tfidf_encoder.vocabulary_)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHTzIjfNRHj2"
      },
      "source": [
        "## Task 2\n",
        "Implement cosine distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UCfgR6xEPeDn"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "\n",
        "def cosine_distance(vector_a: np.array, vector_b: np.array) -> float:\n",
        "  \"\"\"\n",
        "    Cosine distance: one minus dot product ratio\n",
        "    to the product of L2 norms\n",
        "  \"\"\"\n",
        "  return  1 - sum(vector_a * vector_b) / (np.linalg.norm(vector_a) * np.linalg.norm(vector_b))\n",
        "\n",
        "# Simple text\n",
        "assert cosine_distance(np.array([1, 0, 1, 1, 1]), np.array([0, 0, 1, 0, 0])) == 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHsaHoORlEC"
      },
      "source": [
        "Now we calculate the cosine distance closest between the vector representations of documents and queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIZJRBKQQR1G",
        "outputId": "e166a60d-89d2-4c6f-b976-1b10606671d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: viscous interactions\n",
            "FOUND:\n",
            "    44\t0.50\thas anyone investigated the effect of surface mass transfer on hypersonic viscous interactions . \n",
            "    46\t0.56\twhat are the existing solutions for hypersonic viscous interactions over an insulated flat plate . \n",
            "    71\t0.64\twhat has been done about viscous interactions in relatively low reynolds number flows,  particularly at high mach numbers . \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "for q_id, query in enumerate(tfidf_encoded_queries):\n",
        "  # cast to the desired type\n",
        "  query = query.todense().A1\n",
        "  docs = [doc.todense().A1 for doc in tfidf_encoded_data]\n",
        "  # cosine distance\n",
        "  id2doc2similarity = [(doc_id, doc, cosine_distance(query, doc)) \\\n",
        "                       for doc_id, doc in enumerate(docs)]\n",
        "  # sort\n",
        "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=False)\n",
        "  \n",
        "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
        "  \n",
        "  for closest_id, _, sim in closest[:3]:\n",
        "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}